{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkQlfgfLVDqbM9vHlvb4WD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvonbulow/csse490-nlp/blob/master/Labs/Lab8SentimentAnalysisUnsupervisedLexical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODPPc1HjrLCv",
        "outputId": "94252c56-0e3b-4a18-dc29-e3b89cc59c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    2.2.4                         \n",
            "Location         /usr/local/lib/python3.7/dist-packages/spacy\n",
            "Platform         Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Python version   3.7.12                        \n",
            "Models           en                            \n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy info"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import prerequisite files\n",
        "!wget https://raw.githubusercontent.com/dipanjanS/practical-machine-learning-with-python/master/notebooks/Ch07_Analyzing_Movie_Reviews_Sentiment/text_normalizer.py\n",
        "!wget https://raw.githubusercontent.com/dipanjanS/practical-machine-learning-with-python/master/notebooks/Ch07_Analyzing_Movie_Reviews_Sentiment/model_evaluation_utils.py\n",
        "!wget https://github.com/dipanjanS/practical-machine-learning-with-python/raw/master/notebooks/Ch07_Analyzing_Movie_Reviews_Sentiment/movie_reviews.csv\n",
        "!wget https://raw.githubusercontent.com/dipanjanS/practical-machine-learning-with-python/3bdd65cfd9697ef41fd0b29217568c7b5e85b61c/notebooks/Ch07_Analyzing_Movie_Reviews_Sentiment/contractions.py\n",
        "!pip install afinn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6hY8MZXrQxM",
        "outputId": "3a89db84-6273-424e-9e9a-7d7060e2f5d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-30 02:08:22--  https://raw.githubusercontent.com/dipanjanS/practical-machine-learning-with-python/master/notebooks/Ch07_Analyzing_Movie_Reviews_Sentiment/text_normalizer.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3916 (3.8K) [text/plain]\n",
            "Saving to: ‘text_normalizer.py.4’\n",
            "\n",
            "\rtext_normalizer.py.   0%[                    ]       0  --.-KB/s               \rtext_normalizer.py. 100%[===================>]   3.82K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-30 02:08:22 (55.3 MB/s) - ‘text_normalizer.py.4’ saved [3916/3916]\n",
            "\n",
            "--2022-01-30 02:08:23--  https://raw.githubusercontent.com/dipanjanS/practical-machine-learning-with-python/master/notebooks/Ch07_Analyzing_Movie_Reviews_Sentiment/model_evaluation_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8575 (8.4K) [text/plain]\n",
            "Saving to: ‘model_evaluation_utils.py.4’\n",
            "\n",
            "model_evaluation_ut 100%[===================>]   8.37K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-30 02:08:23 (90.2 MB/s) - ‘model_evaluation_utils.py.4’ saved [8575/8575]\n",
            "\n",
            "--2022-01-30 02:08:23--  https://github.com/dipanjanS/practical-machine-learning-with-python/raw/master/notebooks/Ch07_Analyzing_Movie_Reviews_Sentiment/movie_reviews.csv\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dipanjanS/practical-machine-learning-with-python/master/notebooks/Ch07_Analyzing_Movie_Reviews_Sentiment/movie_reviews.csv [following]\n",
            "--2022-01-30 02:08:23--  https://raw.githubusercontent.com/dipanjanS/practical-machine-learning-with-python/master/notebooks/Ch07_Analyzing_Movie_Reviews_Sentiment/movie_reviews.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 66212309 (63M) [text/plain]\n",
            "Saving to: ‘movie_reviews.csv.2’\n",
            "\n",
            "movie_reviews.csv.2 100%[===================>]  63.14M   275MB/s    in 0.2s    \n",
            "\n",
            "2022-01-30 02:08:23 (275 MB/s) - ‘movie_reviews.csv.2’ saved [66212309/66212309]\n",
            "\n",
            "--2022-01-30 02:08:23--  https://raw.githubusercontent.com/dipanjanS/practical-machine-learning-with-python/3bdd65cfd9697ef41fd0b29217568c7b5e85b61c/notebooks/Ch07_Analyzing_Movie_Reviews_Sentiment/contractions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3050 (3.0K) [text/plain]\n",
            "Saving to: ‘contractions.py’\n",
            "\n",
            "contractions.py     100%[===================>]   2.98K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-30 02:08:23 (42.0 MB/s) - ‘contractions.py’ saved [3050/3050]\n",
            "\n",
            "Requirement already satisfied: afinn in /usr/local/lib/python3.7/dist-packages (0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "import text_normalizer as tn\n",
        "import model_evaluation_utils as meu\n",
        "import textblob\n",
        "\n",
        "np.set_printoptions(precision=2, linewidth=80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpuSS0K8ru6L",
        "outputId": "0fc98e54-7e7d-4b1c-e1f6-8280140329bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Normalize Data"
      ],
      "metadata": {
        "id": "kBPJWaIzv22z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('movie_reviews.csv')\n",
        "reviews = np.array(df['review'])\n",
        "sentiments = np.array(df['sentiment'])\n",
        "\n",
        "# extract"
      ],
      "metadata": {
        "id": "cwAMppLwvQb8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}